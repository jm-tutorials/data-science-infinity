# Background:
Decco is an online retailer that sells home decor items. They recently added ‘Lamps’ as a new category of products which they were not selling before. In order to generate awareness and boost sales, they want to do a promotion through their App. Their notifications have had good success in the past and they are considering to send a message making users aware of this new category, through in-app notification. But atthe same time, they want to be judicious about any features or releases when it comes to their app because they know that LTV of a customer who has installed their app is much higher. They want to be careful so as not to drive users to uninstall the app.

Can they run an A/B test in this scenario?

# Business hypothesis:
Because we have seem good success through in-app notifications in the past, if
send an in-app notification with a promotional offer for Lamps, then the % of 
users that purchase from the Lamp Category will increase
Primary metric - Transaction Rate i.e % of users that will make a purchase
Secondary metrics - Purchase Value
Other metrics - Uninstall rate

```{r}
# install.packages("pwr")
library(pwr)
# install.packages("glue")
library(glue)

setwd("~/Documents/learning/data-science-infinity/ab-testing")

control <- 0.101
uplift <- .2 # we want at least 20% uplfit
variant <- (1 + uplift) * control
effect_size <- ES.h(control, variant)
sample_size_output <- pwr.2p.test(h = effect_size,
                                 n = ,
                                 sig.level = 0.05,
                                 power = 0.8)

sample_size_output <- ceiling(sample_size_output$n)
glue('sample size needed: {sample_size_output}')
```

## Understanding the data

```{r}
df <- read.csv("udemy_ab_test_data.csv")
```
Treatment indicator - allocation
Response variables - addtocart_flag, transaction_flag, purchase_value
Baseline variables - active_6m, days_since
Other - uninstall_flag

Numerical variable stats
```{r}
summary(df[,c("active_6m", "addtocart_flag", "transaction_flag", "uninstall_flag",
              "purchase_value", "days_since")])

# install.packages(c("ggplot2","dplyr"))
library(ggplot2)
library(dplyr)

# plot purchase value
df %>% 
  ggplot(aes(x = purchase_value)) +
  geom_histogram( color="#e9ecef", fill="#E69F00", alpha=0.6, position='identity') +
  scale_fill_manual(values=c("#69b3a2", "404080")) +
  labs(fill="")

df %>% ggplot(aes(x=purchase_value)) +
  geom_density(color="#E69F00")

# plot days_since
df %>% ggplot(aes(x = days_since)) +
  geom_histogram( color="#e9ecef", fill="#56B4E9", alpha=0.6, position='identity') +
  scale_fill_manual(values=c("#69b3a2", "404080")) +
  labs(fill="")

df %>% ggplot(aes(x=days_since)) +
  geom_density(color="#56B4E9")

# categorical variable stats
table(df$allocation)
table(df$allocation)/nrow(df)
```

## Check for randomization - baseline variables
```{r}
df %>% 
  group_by(allocation) %>%
  summarise(mean(active_6m), mean(days_since))

# compare distribution across the two groups

df %>% 
  ggplot(aes(x=days_since, fill=allocation)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position='identity') +
  scale_fill_manual(values=c("#69b3a2", "404080")) +
  labs(fill="")
```
## Treatment Effects
Compare performance of response variables across the two groups
```{r}
df  %>%
  group_by(allocation) %>%
  summarise(mean(addtocart_flag),
            mean(transaction_flag),
            mean(purchase_value, na.rm=TRUE))

transaction_proportion <- gprop.test(xtabs(~ allocation + transaction_flag, data=df)[,2:1])
```

This is telling us that the treatment group performed between `100*min(transaction_proportion$conf.int[1:2]*-1)`% and `100*max(transaction_proportion$conf.int[1:2]*-1)`% better than the control i.e. if we were to repeat this test 20 times with 20 different samples, the difference between performance of the two groups will lie somewhere between these two numbers, at least 19 times. In other words those difference are statistically significant.

```{r}
add_to_cart_proportion <- prop.test(xtabs(~ allocation + addtocart_flag, data=df)[,2:1])
add_to_cart_proportion

purchase_value_ttest <- t.test(purchase_value ~ allocation, data=df)
purchase_value_ttest
```

Before recommending the treatment variation, we need to check if there is a correlation with the mobile notification and uninstalls

```{r}
df %>%
  group_by(allocation) %>%
  summarise(mean(uninstall_flag))

prop.test(xtabs(~ allocation + uninstall_flag, data=df)[,2:1])
```

While the treatment did perform better in terms of transactions, add to carts, and purchase value; it performed worse in terms of uninstalls. Given the higher LTV of app users we will not recommend the 

  

